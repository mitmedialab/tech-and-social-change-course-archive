<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>
	Comments on: let&#8217;s do some ai+ethics	</title>
	<atom:link href="https://techandsocialchange.mit.edu/2018/10/09/lets-do-some-aiethics/feed/" rel="self" type="application/rss+xml" />
	<link>https://techandsocialchange.mit.edu/2018/10/09/lets-do-some-aiethics/</link>
	<description>MAS.S63 Fall 2018 &#124; Wednesdays 10-1 in E15-341</description>
	<lastBuildDate>Wed, 10 Oct 2018 14:41:08 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.4.1</generator>
	<item>
		<title>
		By: Magnus Bjerg		</title>
		<link>https://techandsocialchange.mit.edu/2018/10/09/lets-do-some-aiethics/#comment-2132</link>

		<dc:creator><![CDATA[Magnus Bjerg]]></dc:creator>
		<pubDate>Wed, 10 Oct 2018 14:41:08 +0000</pubDate>
		<guid isPermaLink="false">http://techandsocialchange2017.wordpress.brownbag.me/?p=1052#comment-2132</guid>

					<description><![CDATA[&quot;We assume positive intent&quot; is both powerful and intriguing to me as a foreigner. I assume it is needed to open the room for a discussion about race and maybe gender? It would probably be useful when discussing AI bias. But might it be helpful to attack the subject critically and assume that any AI or training data contains bias and it is just a matter of finding it. And added value could be something along the lines of &quot;trust nothing, check everything&quot; that is a huge part of the journalistic ethos that I was molded by. In other words: Accountability.

By the way, I love the subject. It is a big interest of mine right now. But could it also be applied to teaching older students? And how would you help the middle schoolers produce tangible products in class?

It might be a bit off topic but to me the most obvious ways students meet AI right now is through their newsfeeds on various social media. AI plays a huge role in various aspects of this and as a digital journalist I have spent years trying to &quot;game&quot; or understand &quot;the algoritme&quot;. It might be an interesting and very concrete take on how AI is affecting our lives.]]></description>
			<content:encoded><![CDATA[<p>&#8220;We assume positive intent&#8221; is both powerful and intriguing to me as a foreigner. I assume it is needed to open the room for a discussion about race and maybe gender? It would probably be useful when discussing AI bias. But might it be helpful to attack the subject critically and assume that any AI or training data contains bias and it is just a matter of finding it. And added value could be something along the lines of &#8220;trust nothing, check everything&#8221; that is a huge part of the journalistic ethos that I was molded by. In other words: Accountability.</p>
<p>By the way, I love the subject. It is a big interest of mine right now. But could it also be applied to teaching older students? And how would you help the middle schoolers produce tangible products in class?</p>
<p>It might be a bit off topic but to me the most obvious ways students meet AI right now is through their newsfeeds on various social media. AI plays a huge role in various aspects of this and as a digital journalist I have spent years trying to &#8220;game&#8221; or understand &#8220;the algoritme&#8221;. It might be an interesting and very concrete take on how AI is affecting our lives.</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>
